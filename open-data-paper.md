# Challenges facing Open Data and possible solutions/recommendations for addressing these challenges

The arguments in favour of Open Data in research are becoming overwhelming. There are calls a national [@RCKUOpen] and international levels [@Moedas2015, @RSOpen]. In this paper I will set out a quick working definition of Open Data. I will discuss some of the key challenges that must be navigated before Open Data becomes standard practice. I will attempt to look at examples in specific fields where some of these challenges have been overcome, and draw from these some potential general solutions that might be adopted broadly. 

## Open Data is ... 
Open Data is Findable, Accessible, Interoperable and Reusable [@Wilkinson2016]. 

## How should we speak of challenges in the way of Open Data? 
[@Goodman2014] lay out ten rules for the care and feeding of scientific data. Were all of these rules to be adhered to by all researchers, we would have as good an Open Data ecosystem as we could wish for. In this light then, let us look at what might be preventing us from adopting these practices! 

Rule 0, an almost unwritten rule from this paper, is to share data. The general lack of willingness of researchers to share their data is the greatest of the challenges, and I will return to this point at the end of this paper, to consider it in light of the other challenges discussed. 

## Rule 1. Love Your Data, and Help Others Love It, Too
The [first rule](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003542#s2) talks about the need to create data that is well described and well documented. A number of potential challenges stand in the way of making this happen as a matter of course. Keeping track of what the researcher did can be complicated. Some data is hyper-hetrogeneous, bringing together multi-varied data across many dimensions, in such a way that only the researcher who created that data set understands how to unpick it. 

## Rule 3. Conduct Science with a Particular Level of Reuse in Mind
The [thrid rule](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003542#s4) 
researchers sometimes create entirely new data formats that are only of particular use in certain contexts





# Introduction 



## Other kinds of problems we could talk about

### Large data 
Data is sometimes too big to share or to process, see CERN. 

### Heterogeneous data 
A research question may need to pull together data from very different sources, and perhaps only the researcher understands how to combine the data 

### Data owned by corporations 
Large data at google  and Facebook scale are owned by companies like google and Facebook. Work that builds on this data cannot be reproduced (this is an edge case). 

### False privacy fears 
Privacy concerns are real, but often the conversation gets dominated by this concern, where most data is not affected by this conversation. 

### New tools create new data formats 
Especially in microscopy (see OMERO as a solution to this)

### Lack of training 
(see data carpentry as a solution to this)

### Lack of infrastructure 
needs to be dealt with on a subject by subject basis, also libraries may play a role in the future 

### Lack of credit 
This is the biggest problem, researcher led grants, and personal impact statements can help 

### You also need to think about code as well as data 

--- 
